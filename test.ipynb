{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BaseExceptionGroup', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'EncodingWarning', 'EnvironmentError', 'Exception', 'ExceptionGroup', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'ModuleNotFoundError', 'NameError', 'NotADirectoryError', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'RecursionError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopAsyncIteration', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'WindowsError', 'ZeroDivisionError', '__build_class__', '__import__', '__loader__', 'abs', 'aiter', 'all', 'anext', 'any', 'ascii', 'bin', 'bool', 'breakpoint', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'display', 'divmod', 'enumerate', 'eval', 'exec', 'execfile', 'filter', 'float', 'format', 'frozenset', 'get_ipython', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'range', 'repr', 'reversed', 'round', 'runfile', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip']\n"
     ]
    }
   ],
   "source": [
    "import builtins\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from pydantic import BaseModel\n",
    "\n",
    "builtin_functions = [name for name in dir(builtins) if callable(getattr(builtins, name))]\n",
    "print(builtin_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_used_functions(script_path):\n",
    "    with open(script_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Regular expression to find function calls\n",
    "    # This looks for any characters (non-greedy) followed by an opening parenthesis,\n",
    "    # capturing everything after the last whitespace or start of the line\n",
    "    pattern = r'(^|[\\s])([^\\s]+?)\\s*\\('\n",
    "\n",
    "    # Find all matches\n",
    "    matches = re.findall(pattern, content, re.MULTILINE)\n",
    "\n",
    "    # Extract the full function names (second group in each match)\n",
    "    used_functions = set(match[1] for match in matches)\n",
    "\n",
    "    return used_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_used_functions_with_indent(script_path):\n",
    "    with open(script_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    function_info = []\n",
    "    \n",
    "    for line_number, line in enumerate(lines, 1):\n",
    "        # Skip lines that start with '#' (comments)\n",
    "        if line.lstrip().startswith('#'):\n",
    "            continue\n",
    "\n",
    "        # Count leading spaces to determine indent level\n",
    "        indent_level = len(line) - len(line.lstrip())\n",
    "        \n",
    "        # Regular expression to find function calls\n",
    "        # This looks for alphanumeric characters and dots, followed immediately by an opening parenthesis\n",
    "        matches = re.finditer(r'\\b([a-zA-Z0-9_\\.]+)\\s*\\(', line)\n",
    "        \n",
    "        for match in matches:\n",
    "            function_name = match.group(1)\n",
    "            # Ensure the function name doesn't end with a dot\n",
    "            if not function_name.endswith('.'):\n",
    "                function_info.append({\n",
    "                    'name': function_name,\n",
    "                    'line': line_number,\n",
    "                    'indent': indent_level\n",
    "                })\n",
    "\n",
    "    return function_info\n",
    "\n",
    "\n",
    "# Example usage\n",
    "script_path = 'C:/Users/justl/Documents/folder/main.py'\n",
    "functions = get_used_functions_with_indent(script_path)\n",
    "\n",
    "print(\"Functions used in the script with their indent levels:\")\n",
    "for func in functions:\n",
    "    print(f\"  Line {func['line']}: {' ' * func['indent']}{func['name']} (indent: {func['indent']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"C:/Users/justl/Documents/folder/\"\n",
    "entry_point = \"main.py\"\n",
    "\n",
    "start_file_path = os.path.join(folder, entry_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, type, content, children=None):\n",
    "        self.type = type\n",
    "        self.content = content\n",
    "        self.children = children or []\n",
    "\n",
    "def parse_python_to_nodes(script_path):\n",
    "    with open(script_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    root = Node(type='root', '')\n",
    "    stack = [root]\n",
    "    current_indent = 0\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        if line.strip() == '' or line.lstrip().startswith('#'):\n",
    "            continue\n",
    "\n",
    "        indent = len(line) - len(line.lstrip())\n",
    "        content = line.strip()\n",
    "\n",
    "        while indent < current_indent:\n",
    "            stack.pop()\n",
    "            current_indent -= 4\n",
    "\n",
    "        if content.startswith('#'):\n",
    "            node = Node(type='comment', content)\n",
    "        elif content.startswith('def '):\n",
    "            node = Node(type='function', content)\n",
    "        elif content.startswith('if ') or content.startswith('elif ') or content.startswith('else:'):\n",
    "            node = Node(type='condition', content)\n",
    "        elif content.startswith('for ') or content.startswith('while '):\n",
    "            node = Node(type='loop', content)\n",
    "        elif content.startswith('import ') or content.startswith('from '):\n",
    "            node = Node(type='import', content)\n",
    "        elif '(' in content:\n",
    "            node = Node(type='function_call', content)\n",
    "        else:\n",
    "            node = Node(type='statement', content)\n",
    "\n",
    "        stack[-1].children.append(node)\n",
    "        \n",
    "        if content.endswith(':'):\n",
    "            stack.append(node)\n",
    "            current_indent = indent + 4\n",
    "\n",
    "    return root\n",
    "\n",
    "def node_to_dict(node):\n",
    "    return {\n",
    "        'type': node.type,\n",
    "        'content': node.content,\n",
    "        'children': [node_to_dict(child) for child in node.children]\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "script_path = 'C:/Users/justl/Documents/folder/main.py'\n",
    "root = parse_python_to_nodes(script_path)\n",
    "\n",
    "# Convert to JSON for easy visualization or further processing\n",
    "json_representation = json.dumps(node_to_dict(root), indent=2)\n",
    "print(json_representation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import *\n",
    "\n",
    "class Alias(BaseModel):\n",
    "    actual_name: str\n",
    "    alias_name: str\n",
    "    local_file: bool\n",
    "\n",
    "class Node(BaseModel):\n",
    "    type: str\n",
    "    content: str\n",
    "    children: List['Node'] = []\n",
    "    functions: List[str] = []\n",
    "    aliases: List[Alias] = []\n",
    "\n",
    "# class Node:\n",
    "#     def __init__(self, type, content, children=None, function=None):\n",
    "#         self.type = type\n",
    "#         self.content = content\n",
    "#         self.children = children or []\n",
    "#         self.function = function\n",
    "\n",
    "def get_alias(node: Node, folder: str):\n",
    "    filename = node.content.split(\" \")[1]\n",
    "    filename = filename.replace(\".\", \"/\")\n",
    "\n",
    "    file_loc = os.path.join(folder, filename+\".py\")\n",
    "\n",
    "    local_file = os.path.exists(file_loc)\n",
    "\n",
    "    statement = node.content\n",
    "    aliases = []\n",
    "\n",
    "    if \" as \" in statement:\n",
    "        parts = statement.split()\n",
    "        indexes = [i for i, part in enumerate(parts) if part == \"as\"]\n",
    "        for index in indexes:\n",
    "            actual_name = parts[index - 1]  # The name before \"as\"\n",
    "            alias_name = parts[index + 1]    # The name after \"as\"\n",
    "\n",
    "            alias = Alias(\n",
    "                alias_name = alias_name,\n",
    "                actual_name = actual_name,\n",
    "                local_file = local_file\n",
    "            )\n",
    "\n",
    "            aliases.append(alias)\n",
    "\n",
    "    return aliases\n",
    "\n",
    "def alias_to_dict(alias: Alias) -> dict:\n",
    "    return {\n",
    "        'actual_name': alias.actual_name,\n",
    "        'alias_name': alias.alias_name,\n",
    "        'local_file': alias.local_file\n",
    "    }\n",
    "\n",
    "def node_to_dict(node):\n",
    "    return {\n",
    "        'type': node.type,\n",
    "        'content': node.content,\n",
    "        'functions': node.functions,\n",
    "        'children': [node_to_dict(child) for child in node.children],\n",
    "        'aliases': [alias_to_dict(alias) for alias in node.aliases if alias],\n",
    "    }\n",
    "\n",
    "def dict_to_node(data: Dict[str, Any]) -> Node:\n",
    "    # Create the Node object from the dictionary\n",
    "    node = Node(\n",
    "        type=data['type'],\n",
    "        content=data['content'],\n",
    "        function=data.get('function'),\n",
    "        alias=Alias(**data['alias']) if data.get('alias') else None\n",
    "    )\n",
    "    \n",
    "    # Recursively convert children\n",
    "    for child_data in data.get('children', []):\n",
    "        child_node = dict_to_node(child_data)\n",
    "        node.children.append(child_node)\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "class Alias(BaseModel):\n",
    "    actual_name: str\n",
    "    alias_name: str\n",
    "    local_file: bool\n",
    "\n",
    "class Node(BaseModel):\n",
    "    type: str\n",
    "    content: str\n",
    "    children: List['Node'] = []\n",
    "    functions: List[str] = []  # List of function names\n",
    "    aliases: List[Alias] = []   # List of Alias objects\n",
    "\n",
    "def get_alias(node: Node, folder: str):\n",
    "    filename = node.content.split(\" \")[1]\n",
    "    filename = filename.replace(\".\", \"/\")\n",
    "    file_loc = os.path.join(folder, filename + \".py\")\n",
    "    local_file = os.path.exists(file_loc)\n",
    "\n",
    "    statement = node.content\n",
    "    aliases = []\n",
    "\n",
    "    # Split by commas to handle both single and multiline imports\n",
    "    parts = statement.replace(\"(\", \"\").replace(\")\", \"\").split(\",\")\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if \" as \" in part:\n",
    "            actual_name, alias_name = part.split(\" as \")\n",
    "            alias = Alias(\n",
    "                alias_name=alias_name.strip(),\n",
    "                actual_name=actual_name.strip(),\n",
    "                local_file=local_file\n",
    "            )\n",
    "            aliases.append(alias)\n",
    "            node.aliases.append(alias)  # Add alias to the Node's aliases list\n",
    "\n",
    "    return aliases\n",
    "\n",
    "def extract_function_name(line):\n",
    "    match = re.findall(r'\\b([a-zA-Z0-9_\\.]+)\\s*\\(', line)\n",
    "    return match if match else []  # Return a list of function names\n",
    "\n",
    "def handle_class(stripped_line, stack):\n",
    "    if 'BaseModel' in stripped_line:\n",
    "        node = Node(type='custom_type', content=stripped_line)\n",
    "    else:\n",
    "        node = Node(type='class', content=stripped_line)\n",
    "    stack[-1].children.append(node)\n",
    "    stack.append(node)\n",
    "\n",
    "def handle_function(stripped_line, stack):\n",
    "    function_names = extract_function_name(stripped_line)\n",
    "    node = Node(type='function', content=stripped_line, functions=function_names)\n",
    "    stack[-1].children.append(node)\n",
    "    stack.append(node)\n",
    "\n",
    "def handle_condition(stripped_line, stack):\n",
    "    node = Node(type='condition', content=stripped_line)\n",
    "    stack[-1].children.append(node)\n",
    "    if stripped_line.endswith(':'):\n",
    "        stack.append(node)\n",
    "\n",
    "def handle_loop(stripped_line, stack):\n",
    "    node = Node(type='loop', content=stripped_line)\n",
    "    stack[-1].children.append(node)\n",
    "    if stripped_line.endswith(':'):\n",
    "        stack.append(node)\n",
    "\n",
    "def handle_import(stripped_line, stack, script_folder, output_folder):\n",
    "    node = Node(type='import', content=stripped_line)\n",
    "    stack[-1].children.append(node)\n",
    "    aliases = []\n",
    "\n",
    "    # Extract aliases from the import statement\n",
    "    tmp_aliases = get_alias(node, script_folder)\n",
    "    if tmp_aliases:\n",
    "        aliases.extend(tmp_aliases)\n",
    "\n",
    "    # Handle the filename and local file check\n",
    "    filename = node.content.split(\" \")[1].replace(\".\", \"/\")\n",
    "    file_loc = os.path.join(script_folder, filename + \".py\")\n",
    "    local_file = os.path.exists(file_loc)\n",
    "\n",
    "    if local_file:\n",
    "        parse_python_to_nodes(script_folder, filename + \".py\", output_folder)\n",
    "\n",
    "    return aliases\n",
    "\n",
    "def parse_python_to_nodes(script_folder, script_name, output_folder=\"nodes\"):\n",
    "    script_path = os.path.join(script_folder, script_name)\n",
    "\n",
    "    filename, _ = os.path.splitext(script_name)\n",
    "    filename = filename.replace(\"/\", \".\").replace(\"\\\\\", \".\")\n",
    "\n",
    "    with open(script_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "    node_file = os.path.join(output_folder, filename + \".json\")\n",
    "\n",
    "    root = Node(type='root', content='')\n",
    "    stack = [root]\n",
    "    current_indent = 0\n",
    "    in_docstring = False\n",
    "    docstring_content = []\n",
    "    aliases = []\n",
    "\n",
    "    def extract_function_name(line):\n",
    "        match = re.findall(r'\\b([a-zA-Z0-9_\\.]+)\\s*\\(', line)\n",
    "        return match if match else []  # Return a list of function names\n",
    "\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        indent = len(line) - len(line.lstrip())\n",
    "\n",
    "        # Handle docstrings\n",
    "        if '\"\"\"' in stripped_line:\n",
    "            if not in_docstring:\n",
    "                in_docstring = True\n",
    "                docstring_content = [stripped_line]\n",
    "            else:\n",
    "                docstring_content.append(stripped_line)\n",
    "                full_docstring = '\\n'.join(docstring_content)\n",
    "                node = Node(type='docstring', content=full_docstring)\n",
    "                if stack:  # Ensure stack is not empty\n",
    "                    stack[-1].children.append(node)\n",
    "                in_docstring = False\n",
    "                docstring_content = []\n",
    "            continue\n",
    "\n",
    "        if in_docstring:\n",
    "            docstring_content.append(line.rstrip())\n",
    "            continue\n",
    "\n",
    "        if stripped_line == '' or stripped_line.startswith('#'):\n",
    "            continue\n",
    "\n",
    "        # Adjust stack based on indentation\n",
    "        while stack and indent < current_indent:\n",
    "            stack.pop()\n",
    "            current_indent -= 4\n",
    "\n",
    "        # Reset stack if it becomes empty\n",
    "        if not stack:\n",
    "            stack.append(root)  # Reset to root\n",
    "            current_indent = 0\n",
    "\n",
    "        # Handle definitions with a mapping\n",
    "        line_first_word = stripped_line.split()[0]\n",
    "        handlers = {\n",
    "            'class': handle_class,\n",
    "            'def': handle_function,\n",
    "            'if': handle_condition,\n",
    "            'elif': handle_condition,\n",
    "            'else': handle_condition,\n",
    "            'for': handle_loop,\n",
    "            'while': handle_loop,\n",
    "            'import': handle_import,\n",
    "            'from': handle_import\n",
    "        }\n",
    "\n",
    "        if line_first_word in handlers:\n",
    "            if line_first_word in ['import', 'from']:\n",
    "                handlers[line_first_word](stripped_line, stack, script_folder, output_folder)\n",
    "            else:\n",
    "                handlers[line_first_word](stripped_line, stack, output_folder)\n",
    "\n",
    "        elif '(' in stripped_line:\n",
    "            function_names = extract_function_name(stripped_line)\n",
    "            node = Node(type='function_call', content=stripped_line, functions=function_names)\n",
    "            \n",
    "            if function_names == []:\n",
    "                node = Node(type='statement', content=stripped_line)\n",
    "                stack[-1].children.append(node)\n",
    "                continue\n",
    "            \n",
    "            for alias in aliases:\n",
    "                for function in function_names:\n",
    "                    if alias.alias_name in function.split(\".\"):\n",
    "                        node.aliases.append(alias)\n",
    "\n",
    "            stack[-1].children.append(node)\n",
    "        else:\n",
    "            node = Node(type='statement', content=stripped_line)\n",
    "            stack[-1].children.append(node)\n",
    "\n",
    "    data = node_to_dict(root)\n",
    "    with open(node_file, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_v2 ['AudioDiarizationProcessor.__init__', 'AudioDiarizationProcessor.process_chunk', 'AudioDiarizationProcessor.save_chunk_state', 'AudioDiarizationProcessor.build_segments', 'AudioDiarizationProcessor.ms_to_timecode', 'AudioDiarizationProcessor.timecode_to_ms', 'AudioDiarizationProcessor.build_segments_by_words', '__init__', 'process_chunk', 'save_chunk_state', 'build_segments', 'ms_to_timecode', 'timecode_to_ms', 'build_segments_by_words', 'build_segments_by_sentences', 'AudioDiarization.__init__', 'AudioDiarization.create_transcription', 'AudioDiarization.remove_background_audio', 'AudioDiarization.locate_silences', 'AudioDiarization.get_audio_duration_ms', 'AudioDiarization.ensure_standard_format', 'AudioDiarization.split_audio', 'AudioDiarization.create_audio_chunks', 'AudioDiarization.plot_audio_db', 'AudioDiarization.extract_transcription', 'AudioDiarization.run_audio_diarization', 'AudioDiarization.transcribeAudioFile', 'AudioDiarization.withRetry', '__init__', 'create_transcription', 'remove_background_audio', 'locate_silences', 'get_audio_duration_ms', 'ensure_standard_format', 'split_audio', 'create_audio_chunks', 'plot_audio_db', 'extract_transcription', 'run_audio_diarization', 'transcribeAudioFile', 'withRetry']\n",
      "constants []\n",
      "custom_types.audio []\n",
      "custom_types.config []\n",
      "custom_types.video []\n",
      "custom_types.vision []\n",
      "main_v3 ['main']\n",
      "talknet ['load_talknet_output', 'exec_subprocess', 'run_talknet']\n",
      "utils ['setup_project', 'mp4_to_wav', 'avi_to_mp4']\n",
      "video_v2 ['VideoDiarization.__init__', 'VideoDiarization.create_segments_from_audio', 'VideoDiarization.create_segments_from_frames', 'VideoDiarization.align_timestamps', 'VideoDiarization.create_speaker_mappings', 'VideoDiarization.determine_final_speaker', 'VideoDiarization.associate_frames_with_segments', 'VideoDiarization.make_annotated_video', 'VideoDiarization.add_text_to_frame', '__init__', 'create_segments_from_audio', 'create_segments_from_frames', 'align_timestamps', 'create_speaker_mappings', 'determine_final_speaker', 'associate_frames_with_segments', 'make_annotated_video', 'add_text_to_frame']\n",
      "vision_v2 ['VisionDiarization.__init__', 'VisionDiarization.run_vision_diarization', 'VisionDiarization.get_all_face_info', 'VisionDiarization.get_frame_data', 'VisionDiarization.interpolate_faces', 'VisionDiarization.shrink_speakers', 'VisionDiarization.evaluate_cluster', 'VisionDiarization.evaluate_clusters', 'VisionDiarization.crop_frame', 'VisionDiarization.speaker_sim_scores', 'VisionDiarization.xys2box', 'VisionDiarization.box_area_match', 'VisionDiarization.crop_file_image', '__init__', 'run_vision_diarization', 'get_all_face_info', 'get_frame_data', 'interpolate_faces', 'shrink_speakers', 'evaluate_cluster', 'evaluate_clusters', 'crop_frame', 'speaker_sim_scores', 'xys2box', 'box_area_match', 'crop_file_image']\n"
     ]
    }
   ],
   "source": [
    "def parse_python_to_nodes(script_folder, script_name, output_folder=\"nodes\"):\n",
    "    script_path = os.path.join(script_folder, script_name)\n",
    "\n",
    "    filename, _ = os.path.splitext(script_name)\n",
    "    filename = filename.replace(\"/\", \".\")\n",
    "    filename = filename.replace(\"\\\\\", \".\")\n",
    "\n",
    "    with open(script_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "    node_file = os.path.join(output_folder, filename + \".json\")\n",
    "    # if os.path.exists(node_file):\n",
    "    #     return False\n",
    "\n",
    "    root = Node(type='root', content='')\n",
    "    stack = [root]\n",
    "    current_indent = 0\n",
    "    in_docstring = False\n",
    "    docstring_content = []\n",
    "    aliases = []\n",
    "\n",
    "    def extract_function_name(line):\n",
    "        match = re.findall(r'\\b([a-zA-Z0-9_\\.]+)\\s*\\(', line)\n",
    "        return match if match else []  # Return a list of function names\n",
    "\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        indent = len(line) - len(line.lstrip())\n",
    "\n",
    "        # Handle docstrings\n",
    "        if '\"\"\"' in stripped_line:\n",
    "            if not in_docstring:\n",
    "                in_docstring = True\n",
    "                docstring_content = [stripped_line]\n",
    "            else:\n",
    "                docstring_content.append(stripped_line)\n",
    "                full_docstring = '\\n'.join(docstring_content)\n",
    "                node = Node(type='docstring', content=full_docstring)\n",
    "                if stack:  # Ensure stack is not empty\n",
    "                    stack[-1].children.append(node)\n",
    "                in_docstring = False\n",
    "                docstring_content = []\n",
    "            continue\n",
    "\n",
    "        if in_docstring:\n",
    "            docstring_content.append(line.rstrip())\n",
    "            continue\n",
    "\n",
    "        if stripped_line == '' or stripped_line.startswith('#'):\n",
    "            continue\n",
    "\n",
    "        # Adjust stack based on indentation\n",
    "        while stack and indent < current_indent:\n",
    "            stack.pop()\n",
    "            current_indent -= 4\n",
    "\n",
    "        # Reset stack if it becomes empty\n",
    "        if not stack:\n",
    "            stack.append(root)  # Reset to root\n",
    "            current_indent = 0\n",
    "\n",
    "        # Handle definitions\n",
    "        if stripped_line.startswith('class '):\n",
    "            if 'BaseModel' in stripped_line:\n",
    "                node = Node(type='custom_type', content=stripped_line)  # Set type to custom_type\n",
    "            else:\n",
    "                node = Node(type='class', content=stripped_line)  # Set type to class\n",
    "            stack[-1].children.append(node)\n",
    "            stack.append(node)  # Push the class node onto the stack\n",
    "            current_indent = indent + 4\n",
    "\n",
    "        elif stripped_line.startswith('def '):\n",
    "            function_names = extract_function_name(stripped_line)\n",
    "            node = Node(type='function', content=stripped_line, functions=function_names)\n",
    "            stack[-1].children.append(node)\n",
    "            stack.append(node)\n",
    "            current_indent = indent + 4\n",
    "\n",
    "        elif stripped_line.startswith('if ') or stripped_line.startswith('elif ') or stripped_line.startswith('else:'):\n",
    "            node = Node(type='condition', content=stripped_line)\n",
    "            stack[-1].children.append(node)\n",
    "            if stripped_line.endswith(':'):\n",
    "                stack.append(node)\n",
    "                current_indent = indent + 4\n",
    "\n",
    "        elif stripped_line.startswith('for ') or stripped_line.startswith('while '):\n",
    "            node = Node(type='loop', content=stripped_line)\n",
    "            stack[-1].children.append(node)\n",
    "            if stripped_line.endswith(':'):\n",
    "                stack.append(node)\n",
    "                current_indent = indent + 4\n",
    "                \n",
    "        elif stripped_line.startswith('import ') or stripped_line.startswith('from '):\n",
    "            node = Node(type='import', content=stripped_line)\n",
    "            stack[-1].children.append(node)\n",
    "\n",
    "            # Extract aliases from the import statement\n",
    "            tmp_aliases = get_alias(node, script_folder)\n",
    "            if tmp_aliases:\n",
    "                aliases.extend(tmp_aliases)\n",
    "\n",
    "            # Handle the filename and local file check\n",
    "            filename = node.content.split(\" \")[1]\n",
    "            filename = filename.replace(\".\", \"/\")\n",
    "\n",
    "            file_loc = os.path.join(script_folder, filename + \".py\")\n",
    "\n",
    "            local_file = os.path.exists(file_loc)\n",
    "\n",
    "            if local_file:\n",
    "                # Call parse_python_to_nodes only if the file exists\n",
    "                parse_python_to_nodes(script_folder, filename + \".py\", output_folder)\n",
    "\n",
    "        elif '(' in stripped_line:\n",
    "            function_names = extract_function_name(stripped_line)\n",
    "            node = Node(type='function_call', content=stripped_line, functions=function_names)\n",
    "            if function_names == []:\n",
    "                node = Node(type='statement', content=stripped_line)\n",
    "                stack[-1].children.append(node)\n",
    "                continue\n",
    "            \n",
    "            for alias in aliases:\n",
    "                for function in function_names:\n",
    "                    if alias.alias_name in function.split(\".\"):\n",
    "                        node.aliases.append(alias)\n",
    "\n",
    "            stack[-1].children.append(node)\n",
    "        else:\n",
    "            node = Node(type='statement', content=stripped_line)\n",
    "            stack[-1].children.append(node)\n",
    "\n",
    "    data = node_to_dict(root)\n",
    "    with open(node_file, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "    return True\n",
    "\n",
    "def collect_functions_and_classes(output_folder):\n",
    "    # Dictionary to hold the results\n",
    "    functions_dict = {}\n",
    "\n",
    "    # Get all JSON files in the output folder\n",
    "    json_files = glob.glob(os.path.join(output_folder, \"*.json\"))\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        # Extract the filename without the extension\n",
    "        filename = os.path.splitext(os.path.basename(json_file))[0]\n",
    "        \n",
    "        with open(json_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        root_node = dict_to_node(data)\n",
    "\n",
    "        # Initialize a list to hold function names for this file\n",
    "        function_list = []\n",
    "\n",
    "        # Recursive function to traverse the nodes\n",
    "        def traverse_nodes(node):\n",
    "            # Add functions\n",
    "            if node.type == 'function':\n",
    "                method_name_start = node.content.split()[1]\n",
    "                method_name = method_name_start.split(\"(\")[0]\n",
    "                function_list.append(method_name)  # Get the function name\n",
    "\n",
    "            # Add class methods\n",
    "            if node.type == 'class':\n",
    "                class_name = node.content.split()[1].split(':')[0]  # Get the class name\n",
    "                for child in node.children:\n",
    "                    if child.type == 'function':\n",
    "                        method_name_start = child.content.split()[1]  # Get the method name\n",
    "                        method_name = method_name_start.split(\"(\")[0]\n",
    "                        function_list.append(f\"{class_name}.{method_name}\")\n",
    "\n",
    "            # Traverse children\n",
    "            for child in node.children:\n",
    "                traverse_nodes(child)\n",
    "\n",
    "        # Start traversing from the root node\n",
    "        traverse_nodes(root_node)\n",
    "\n",
    "        # Store the collected functions in the dictionary\n",
    "        functions_dict[filename] = function_list\n",
    "\n",
    "    return functions_dict\n",
    "\n",
    "\n",
    "def main(script_path, script_name):\n",
    "    parse_python_to_nodes(script_path, script_name, output_folder=\"nodes\")\n",
    "    x = collect_functions_and_classes(output_folder=\"nodes\")\n",
    "    for key in x.keys():\n",
    "        print(key, x[key])\n",
    "\n",
    "script_path = 'C:/Users/justl/Documents/VideoDiarization'\n",
    "script_name = \"main_v3.py\"\n",
    "root = main(script_path, script_name)\n",
    "\n",
    "# Convert to JSON for easy visualization or further processing\n",
    "# json_representation = json.dumps(node_to_dict(root), indent=2)\n",
    "# print(json_representation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_import_nodes(node):\n",
    "    import_nodes = []\n",
    "    \n",
    "    if node.type == 'import':\n",
    "        import_nodes.append(node)\n",
    "    \n",
    "    for child in node.children:\n",
    "        import_nodes.extend(find_import_nodes(child))\n",
    "    \n",
    "    return import_nodes\n",
    "\n",
    "# Assuming you have already created the 'root' variable\n",
    "import_nodes = find_import_nodes(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np numpy\n"
     ]
    }
   ],
   "source": [
    "original_dir = \"C:/Users/justl/Documents/folder\"\n",
    "\n",
    "for import_node in import_nodes:\n",
    "    statement = import_node.content\n",
    "\n",
    "    filename = statement.split(\" \")[1]\n",
    "    filename = filename.replace(\".\", \"/\")\n",
    "    file_loc = os.path.join(original_dir, filename+\".py\")\n",
    "\n",
    "    local_file = os.path.exists(file_loc)\n",
    "\n",
    "    aliases = []\n",
    "\n",
    "    if \" as \" in statement:\n",
    "        parts = statement.split()\n",
    "        indexes = [i for i, part in enumerate(parts) if part == \"as\"]\n",
    "        for index in indexes:\n",
    "            actual_name = parts[index - 1]  # The name before \"as\"\n",
    "            alias_name = parts[index + 1]    # The name after \"as\"\n",
    "\n",
    "            alias = Alias(\n",
    "                alias_name = alias_name,\n",
    "                actual_name = actual_name,\n",
    "                local_file = local_file\n",
    "            )\n",
    "\n",
    "            aliases.append(alias)\n",
    "\n",
    "    # if \"as\" in parts:\n",
    "    #     splits = statement.split(\" as \")\n",
    "    #     print(splits)\n",
    "        \n",
    "    # if statement.startswith(\"import \"):\n",
    "    #     for part in parts[1:]:\n",
    "    #         if \"as\" in parts:\n",
    "    #             alias = part.split(\" as \")\n",
    "    #             print(alias)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y, x\n",
      "b, a\n"
     ]
    }
   ],
   "source": [
    "statement = \"from numpy import x as y, a as b, w\"\n",
    "\n",
    "if \" as \" in statement:\n",
    "    parts = statement.split()\n",
    "    indexes = [i for i, part in enumerate(parts) if part == \"as\"]\n",
    "    for index in indexes:\n",
    "        actual_name = parts[index - 1]  # The name before \"as\"\n",
    "        alias_name = parts[index + 1]    # The name after \"as\"\n",
    "\n",
    "        print(alias_name, actual_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main script for the diarization of an mp4 video file.\n",
      "asfoiawfeshjnikpwlnifawlnikafwjlbolia\n",
      "C:/Users/justl/Documents/VideoDiarization\\click.py False\n",
      "C:/Users/justl/Documents/VideoDiarization\\os.py False\n",
      "C:/Users/justl/Documents/VideoDiarization\\typing.py False\n",
      "C:/Users/justl/Documents/VideoDiarization\\time.py False\n",
      "C:/Users/justl/Documents/VideoDiarization\\glob.py False\n",
      "C:/Users/justl/Documents/VideoDiarization\\logging.py False\n",
      "C:/Users/justl/Documents/VideoDiarization\\numpy.py False\n",
      "C:/Users/justl/Documents/VideoDiarization\\custom_types/config.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\custom_types/vision.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\custom_types/vision.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\custom_types/vision.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\custom_types/audio.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\custom_types/audio.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\custom_types/video.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\vision_v2.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\audio_v2.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\audio_v2.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\video_v2.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\talknet.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\talknet.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\utils.py True\n",
      "C:/Users/justl/Documents/VideoDiarization\\utils.py True\n",
      "Functions: ['main']\n",
      "Classes: []\n",
      "Imports: ['click', 'os', 'typing.*', 'time', 'glob', 'logging', 'numpy', 'custom_types.config.Config', 'custom_types.vision.FaceLocation', 'custom_types.vision.Frame', 'custom_types.vision.TalkNetOutput', 'custom_types.audio.AudioChunk', 'custom_types.audio.Stage1Output', 'custom_types.video.VideoSegment', 'vision_v2.VisionDiarization', 'audio_v2.AudioDiarization', 'audio_v2.AudioDiarizationProcessor', 'video_v2.VideoDiarization', 'talknet.run_talknet', 'talknet.load_talknet_output', 'utils.setup_project', 'utils.mp4_to_wav']\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def get_functions_classes_and_imports_from_file(script_folder, script_name):\n",
    "    file_path = os.path.join(script_folder, script_name)\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Parse the file into an AST\n",
    "        node = ast.parse(file.read(), filename=file_path)\n",
    "\n",
    "    functions = []\n",
    "    classes = []\n",
    "    imports = []\n",
    "\n",
    "    for item in node.body:\n",
    "        # print(type(item))\n",
    "        if isinstance(item, ast.FunctionDef):\n",
    "            print(ast.get_docstring(item))\n",
    "            functions.append(item.name)  # Add the function name\n",
    "\n",
    "        elif isinstance(item, ast.ClassDef):\n",
    "            classes.append(item.name)  # Add the class name\n",
    "            # Collect methods within the class\n",
    "            for method in item.body:\n",
    "                if isinstance(method, ast.FunctionDef):\n",
    "                    functions.append(f\"{item.name}.{method.name}\")  # Class method\n",
    "\n",
    "        elif isinstance(item, ast.Import):\n",
    "            for alias in item.names:\n",
    "                imports.append(alias.name)  # Add the imported module name\n",
    "\n",
    "        elif isinstance(item, ast.ImportFrom):\n",
    "            # Handle imports from specific modules\n",
    "            module = item.module if item.module else \"\"\n",
    "            for alias in item.names:\n",
    "                imports.append(f\"{module}.{alias.name}\")  # Add the specific import\n",
    "\n",
    "    return functions, classes, imports\n",
    "\n",
    "# Example usage\n",
    "script_folder = \"C:/Users/justl/Documents/VideoDiarization\"  # Replace with your actual Python file path\n",
    "script_name = \"main_v3.py\"\n",
    "\n",
    "functions, classes, imports = get_functions_classes_and_imports_from_file(script_folder, script_name)\n",
    "\n",
    "for import_name in imports:\n",
    "    module_loc = import_name.split(\".\")\n",
    "    if len(module_loc) > 1:\n",
    "        module_loc = module_loc[:-1]\n",
    "        \n",
    "    module_loc = \"/\".join(module_loc)\n",
    "    \n",
    "    module_path = os.path.join(script_folder, module_loc + \".py\")\n",
    "    \n",
    "    if os.path.exists(module_path):\n",
    "        print(module_path, True)\n",
    "    else:\n",
    "        print(module_path, False)\n",
    "\n",
    "print(\"Functions:\", functions)\n",
    "print(\"Classes:\", classes)\n",
    "print(\"Imports:\", imports)\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# functions, classes = get_functions_and_classes_from_file(file_path)\n",
    "\n",
    "# print(\"Functions:\", functions)\n",
    "# print(\"Classes:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASTNode(BaseModel):\n",
    "    type: str\n",
    "    content: str\n",
    "    children: List['Node'] = []\n",
    "    functions: List[str] = []\n",
    "    aliases: List[Alias] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Definitions: ['main']\n",
      "Classes: []\n",
      "Imports: [('click', 'custom'), ('os', 'library'), ('typing.*', 'custom'), ('time', 'custom'), ('glob', 'custom'), ('logging', 'custom'), ('numpy', 'library'), ('custom_types.config.Config', 'custom'), ('custom_types.vision.FaceLocation', 'custom'), ('custom_types.vision.Frame', 'custom'), ('custom_types.vision.TalkNetOutput', 'custom'), ('custom_types.audio.AudioChunk', 'custom'), ('custom_types.audio.Stage1Output', 'custom'), ('custom_types.video.VideoSegment', 'custom'), ('vision_v2.VisionDiarization', 'custom'), ('audio_v2.AudioDiarization', 'custom'), ('audio_v2.AudioDiarizationProcessor', 'custom'), ('video_v2.VideoDiarization', 'custom'), ('talknet.run_talknet', 'custom'), ('talknet.load_talknet_output', 'custom'), ('utils.setup_project', 'custom'), ('utils.mp4_to_wav', 'custom')]\n",
      "Function Calls: ['logging.basicConfig', 'logging.getLogger', 'setup_project', 'os.path.join', 'logger.setLevel', 'logger.setLevel', 'os.path.splitext', 'logger.info', 'time.time', 'run_talknet', 'time.time', 'round', 'logger.info', 'logger.debug', 'os.path.join', 'os.path.exists', 'os.mkdir', 'logger.info', 'logger.info', 'load_talknet_output', 'logger.info', 'os.path.join', 'glob.glob', 'os.path.join', 'frame_files.sort', 'logger.debug', 'logger.info', 'VisionDiarization', 'logger.info', 'time.time', 'vision_diarizer.get_all_face_info', 'vision_diarizer.get_frame_data', 'vision_diarizer.interpolate_faces', 'vision_diarizer.shrink_speakers', 'time.time', 'logger.info', 'round', 'logger.warning', 'time.time', 'os.path.join', 'mp4_to_wav', 'logger.info', 'AudioDiarization', 'os.path.join', 'audio_diarizer.create_transcription', 'audio_diarizer.remove_background_audio', 'os.path.join', 'audio_diarizer.create_transcription', 'audio_diarizer.create_audio_chunks', 'speech_audio_chunks.append', 'AudioDiarizationProcessor', 'enumerate', 'audio_diarizer.extract_transcription', 'audio_diarizer.extract_transcription', 'audio_diarization_processor.process_chunk', 'audio_results.append', 'time.time', 'logger.info', 'round', 'logger.info', 'logger.info', 'VideoDiarization', 'video_diarizer.align_timestamps', 'video_diarizer.align_timestamps', 'video_diarizer.align_timestamps', 'video_diarizer.create_speaker_mappings', 'video_diarizer.determine_final_speaker', 'video_diarizer.make_annotated_video', 'click.command', 'click.option', 'main']\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# List of standard library modules\n",
    "standard_library_modules = {\n",
    "    'sys', 'os', 'math', 'json', 're', 'datetime', 'collections', 'itertools', 'functools', 'numpy', 'pandas', 'requests'\n",
    "    # Add more standard library modules as needed\n",
    "}\n",
    "\n",
    "def is_standard_library(module_name):\n",
    "    \"\"\"Check if the given module is a standard library module.\"\"\"\n",
    "    return module_name in standard_library_modules\n",
    "\n",
    "class CodeVisitor(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self.functions = []\n",
    "        self.classes = []\n",
    "        self.imports = []\n",
    "        self.function_calls = []\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        self.functions.append(node.name)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_ClassDef(self, node):\n",
    "        self.classes.append(node.name)\n",
    "        for item in node.body:\n",
    "            if isinstance(item, ast.FunctionDef):\n",
    "                self.functions.append(f\"{node.name}.{item.name}\")\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_Import(self, node):\n",
    "        for alias in node.names:\n",
    "            module_name = alias.name\n",
    "            if is_standard_library(module_name):\n",
    "                self.imports.append((module_name, \"library\"))\n",
    "            else:\n",
    "                self.imports.append((module_name, \"custom\"))\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_ImportFrom(self, node):\n",
    "        module = node.module if node.module else \"\"\n",
    "        for alias in node.names:\n",
    "            if is_standard_library(module):\n",
    "                self.imports.append((f\"{module}.{alias.name}\", \"library\"))\n",
    "            else:\n",
    "                self.imports.append((f\"{module}.{alias.name}\", \"custom\"))\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_Call(self, node):\n",
    "        if isinstance(node.func, ast.Name):\n",
    "            self.function_calls.append(node.func.id)\n",
    "        elif isinstance(node.func, ast.Attribute):\n",
    "            self.function_calls.append(f\"{self.get_full_attribute_name(node.func)}\")\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def get_full_attribute_name(self, node):\n",
    "        if isinstance(node.value, ast.Name):\n",
    "            return f\"{node.value.id}.{node.attr}\"\n",
    "        elif isinstance(node.value, ast.Attribute):\n",
    "            return f\"{self.get_full_attribute_name(node.value)}.{node.attr}\"\n",
    "        return node.attr\n",
    "\n",
    "def get_functions_classes_imports_and_calls_from_file(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Parse the file into an AST\n",
    "        node = ast.parse(file.read(), filename=file_path)\n",
    "\n",
    "    visitor = CodeVisitor()\n",
    "    visitor.visit(node)\n",
    "\n",
    "    return visitor.functions, visitor.classes, visitor.imports, visitor.function_calls\n",
    "\n",
    "# Example usage\n",
    "file_path = \"C:/Users/justl/Documents/VideoDiarization/main_v3.py\"  # Replace with your actual Python file path\n",
    "functions, classes, imports, function_calls = get_functions_classes_imports_and_calls_from_file(file_path)\n",
    "\n",
    "print(\"Function Definitions:\", functions)\n",
    "print(\"Classes:\", classes)\n",
    "print(\"Imports:\", imports)\n",
    "print(\"Function Calls:\", function_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. Results saved to output.json\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Alias(BaseModel):\n",
    "    actual_name: str\n",
    "    alias_name: str\n",
    "    local_file: bool\n",
    "\n",
    "class Node(BaseModel):\n",
    "    type: str\n",
    "    content: str\n",
    "    children: List['Node'] = []\n",
    "    function: Optional[str] = None\n",
    "    alias: Optional[Alias] = None\n",
    "    line_number: Optional[int] = None\n",
    "    end_line_number: Optional[int] = None\n",
    "\n",
    "class PyFileAnalyzer(ast.NodeVisitor):\n",
    "    def __init__(self, source_code, file_path, save_folder):\n",
    "        self.root = Node(type=\"module\", content=\"\", children=[])\n",
    "        self.current_node = self.root\n",
    "        self.save_folder = save_folder\n",
    "        self.file_path = file_path\n",
    "        self.folder_path = os.path.dirname(file_path)\n",
    "        self.source_code = source_code.splitlines()\n",
    "\n",
    "    def get_node_content(self, node):\n",
    "        start_line = node.lineno - 1\n",
    "        end_line = node.end_lineno\n",
    "        content = ' '.join(self.source_code[start_line:end_line]).strip()\n",
    "        return content\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        func_node = Node(\n",
    "            type=\"function\",\n",
    "            content=content,\n",
    "            line_number=node.lineno,\n",
    "            end_line_number=node.end_lineno,\n",
    "            function=node.name\n",
    "        )\n",
    "        self.current_node.children.append(func_node)\n",
    "        old_node = self.current_node\n",
    "        self.current_node = func_node\n",
    "        self.generic_visit(node)\n",
    "        self.current_node = old_node\n",
    "\n",
    "    def visit_ClassDef(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        class_node = Node(\n",
    "            type=\"class\",\n",
    "            content=content,\n",
    "            line_number=node.lineno,\n",
    "            end_line_number=node.end_lineno\n",
    "        )\n",
    "        self.current_node.children.append(class_node)\n",
    "        old_node = self.current_node\n",
    "        self.current_node = class_node\n",
    "        self.generic_visit(node)\n",
    "        self.current_node = old_node\n",
    "\n",
    "    def visit_Import(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        for alias in node.names:\n",
    "            ### local file check\n",
    "            tmp_local_file_path = alias.name\n",
    "            tmp_abs_file_path = os.path.join(self.folder_path, tmp_local_file_path + \".py\")\n",
    "\n",
    "            if os.path.exists(tmp_abs_file_path):\n",
    "                local_file = True\n",
    "                analyze_python_file(tmp_abs_file_path, self.save_folder)\n",
    "            else:\n",
    "                local_file = False\n",
    "\n",
    "            import_node = Node(\n",
    "                type=\"import\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                alias=Alias(actual_name=alias.name, alias_name=alias.asname or alias.name, local_file=local_file)\n",
    "            )\n",
    "            self.current_node.children.append(import_node)\n",
    "\n",
    "    def visit_ImportFrom(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        module = node.module or \"\"\n",
    "        \n",
    "        tmp_local_file_path = f\"{module}\".replace(\".\", \"/\")\n",
    "        tmp_abs_file_path = os.path.join(self.folder_path, tmp_local_file_path + \".py\")\n",
    "\n",
    "        if os.path.exists(tmp_abs_file_path):\n",
    "            local_file = True\n",
    "            analyze_python_file(tmp_abs_file_path, self.save_folder)\n",
    "        else:\n",
    "            local_file = False\n",
    "\n",
    "        for alias in node.names:\n",
    "            import_node = Node(\n",
    "                type=\"import\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                alias=Alias(actual_name=f\"{module}.{alias.name}\", alias_name=alias.asname or alias.name, local_file=local_file)\n",
    "            )\n",
    "            self.current_node.children.append(import_node)\n",
    "\n",
    "    def visit_Call(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        if isinstance(node.func, ast.Name):\n",
    "            call_node = Node(\n",
    "                type=\"function_call\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                function=node.func.id\n",
    "            )\n",
    "            self.current_node.children.append(call_node)\n",
    "        elif isinstance(node.func, ast.Attribute):\n",
    "            call_node = Node(\n",
    "                type=\"function_call\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                function=self.get_full_attribute_name(node.func)\n",
    "            )\n",
    "            self.current_node.children.append(call_node)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def get_full_attribute_name(self, node):\n",
    "        if isinstance(node.value, ast.Name):\n",
    "            return f\"{node.value.id}.{node.attr}\"\n",
    "        elif isinstance(node.value, ast.Attribute):\n",
    "            return f\"{self.get_full_attribute_name(node.value)}.{node.attr}\"\n",
    "        return node.attr\n",
    "\n",
    "def analyze_python_file(file_path: str, save_folder: str) -> Node:\n",
    "    file_path = os.path.abspath(file_path)\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_name = os.path.splitext(file_name)[0]\n",
    "\n",
    "    json_path = os.path.join(save_folder, file_name + \".json\")\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        source_code = file.read()\n",
    "        tree = ast.parse(source_code, filename=file_path)\n",
    "    \n",
    "    analyzer = PyFileAnalyzer(source_code, file_path, save_folder)\n",
    "    analyzer.visit(tree)\n",
    "\n",
    "    root_node = analyzer.root\n",
    "\n",
    "    json_output = json.dumps(node_to_dict(root_node), indent=2)\n",
    "\n",
    "    with open(json_path, \"w\") as json_file:\n",
    "        json_file.write(json_output)\n",
    "\n",
    "    return analyzer.root\n",
    "\n",
    "def node_to_dict(node: Node) -> dict:\n",
    "    result = {\n",
    "        \"type\": node.type,\n",
    "        \"content\": node.content,\n",
    "        \"children\": [node_to_dict(child) for child in node.children],\n",
    "        \"line_number\": node.line_number,\n",
    "        \"end_line_number\": node.end_line_number\n",
    "    }\n",
    "    if node.function:\n",
    "        result[\"function\"] = node.function\n",
    "    if node.alias:\n",
    "        result[\"alias\"] = node.alias.dict()\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_path = \"C:/Users/justl/Documents/VideoDiarization/main_v3.py\"  # Replace with your actual Python file path\n",
    "root_node = analyze_python_file(file_path, save_folder=\"test_folder\")\n",
    "\n",
    "# # Convert to JSON\n",
    "# json_output = json.dumps(node_to_dict(root_node), indent=2)\n",
    "\n",
    "# # Save to file\n",
    "# with open(\"test_folder/output.json\", \"w\") as json_file:\n",
    "#     json_file.write(json_output)\n",
    "\n",
    "print(\"Analysis complete. Results saved to output.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/justl/Documents/VideoDiarization/main_v3.py\"\n",
    "file_path = os.path.abspath(file_path)\n",
    "\n",
    "folder_path = os.path.dirname(file_path)\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    # Parse the file into an AST\n",
    "    node = ast.parse(file.read(), filename=file_path)\n",
    "\n",
    "\n",
    "for item in node.body:\n",
    "    if isinstance(item, ast.Import) or isinstance(item, ast.ImportFrom):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\main_v3.py\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "from typing import List, Optional, Dict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Alias(BaseModel):\n",
    "    actual_name: str\n",
    "    alias_name: str\n",
    "    local_file: bool\n",
    "\n",
    "class Node(BaseModel):\n",
    "    type: str\n",
    "    content: str\n",
    "    children: List['Node'] = []\n",
    "    function: Optional[str] = None\n",
    "    alias: Optional[Alias] = None\n",
    "    line_number: Optional[int] = None\n",
    "    end_line_number: Optional[int] = None\n",
    "    docstring: Optional[str] = None\n",
    "    return_type: Optional[str] = None\n",
    "\n",
    "class PyFileAnalyzer(ast.NodeVisitor):\n",
    "    def __init__(self, source_code, file_path, save_folder):\n",
    "        self.root = Node(type=\"module\", content=\"\", children=[])\n",
    "        self.current_node = self.root\n",
    "        self.save_folder = save_folder\n",
    "        self.file_path = file_path\n",
    "        self.folder_path = os.path.dirname(file_path)\n",
    "        self.source_code = source_code.splitlines()\n",
    "        self.alias_dict = {}\n",
    "        self.variable_types = {}\n",
    "\n",
    "    def get_node_content(self, node):\n",
    "        start_line = node.lineno - 1\n",
    "        end_line = node.end_lineno\n",
    "        content = ' '.join(self.source_code[start_line:end_line]).strip()\n",
    "        return content\n",
    "\n",
    "    def visit_ImportFrom(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        module = node.module or \"\"\n",
    "        \n",
    "        for alias in node.names:\n",
    "            new_alias = Alias(\n",
    "                actual_name=f\"{module}.{alias.name}\", \n",
    "                alias_name=alias.asname or alias.name, \n",
    "                local_file=True  # Assuming it's a local file for simplicity\n",
    "            )\n",
    "            self.alias_dict[alias.asname or alias.name] = new_alias\n",
    "\n",
    "            import_node = Node(\n",
    "                type=\"import\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                alias=new_alias\n",
    "            )\n",
    "            self.current_node.children.append(import_node)\n",
    "\n",
    "    def visit_AnnAssign(self, node):\n",
    "        if isinstance(node.target, ast.Name) and isinstance(node.annotation, ast.Name):\n",
    "            var_name = node.target.id\n",
    "            type_name = node.annotation.id\n",
    "            if type_name in self.alias_dict:\n",
    "                self.variable_types[var_name] = self.alias_dict[type_name].actual_name\n",
    "\n",
    "    def visit_Call(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        if isinstance(node.func, ast.Name):\n",
    "            function_name = node.func.id\n",
    "            if function_name in self.alias_dict:\n",
    "                function_name = self.alias_dict[function_name].actual_name\n",
    "            call_node = Node(\n",
    "                type=\"function_call\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                function=function_name\n",
    "            )\n",
    "            self.current_node.children.append(call_node)\n",
    "        elif isinstance(node.func, ast.Attribute):\n",
    "            full_name = self.get_full_attribute_name(node.func)\n",
    "            parts = full_name.split('.')\n",
    "            if parts[0] in self.variable_types:\n",
    "                parts[0] = self.variable_types[parts[0]]\n",
    "            function_name = '.'.join(parts)\n",
    "            call_node = Node(\n",
    "                type=\"function_call\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                function=function_name\n",
    "            )\n",
    "            self.current_node.children.append(call_node)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def get_full_attribute_name(self, node):\n",
    "        if isinstance(node.value, ast.Name):\n",
    "            return f\"{node.value.id}.{node.attr}\"\n",
    "        elif isinstance(node.value, ast.Attribute):\n",
    "            return f\"{self.get_full_attribute_name(node.value)}.{node.attr}\"\n",
    "        return node.attr\n",
    "    \n",
    "    \n",
    "def analyze_python_file(file_path: str, save_folder: str) -> Node:\n",
    "    file_path = os.path.abspath(file_path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    json_path = os.path.join(save_folder, f\"{file_name}.json\")\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            source_code = file.read()\n",
    "            tree = ast.parse(source_code, filename=file_path)\n",
    "        \n",
    "        analyzer = PyFileAnalyzer(source_code, file_path, save_folder)\n",
    "        analyzer.visit(tree)\n",
    "\n",
    "        root_node = analyzer.root\n",
    "\n",
    "        json_output = json.dumps(node_to_dict(root_node), indent=2)\n",
    "\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json_file.write(json_output)\n",
    "\n",
    "        print(f\"Analyzed and saved JSON for: {file_path}\")\n",
    "        return analyzer.root\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing file {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def node_to_dict(node: Node) -> dict:\n",
    "    result = {\n",
    "        \"type\": node.type,\n",
    "        \"content\": node.content,\n",
    "        \"children\": [node_to_dict(child) for child in node.children],\n",
    "        \"line_number\": node.line_number,\n",
    "        \"end_line_number\": node.end_line_number\n",
    "    }\n",
    "    if node.function:\n",
    "        result[\"function\"] = node.function\n",
    "    if node.alias:\n",
    "        result[\"alias\"] = node.alias.dict()\n",
    "    if node.docstring:\n",
    "        result[\"docstring\"] = node.docstring\n",
    "    if node.return_type:\n",
    "        result[\"return_type\"] = node.return_type\n",
    "    return result\n",
    "\n",
    "def map_execution(file_path: str, save_folder: str):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    analyze_python_file(file_path, save_folder)\n",
    "\n",
    "# Example usage\n",
    "file_path = \"C:/Users/justl/Documents/VideoDiarization/main_v3.py\"  # Replace with your actual Python file path\n",
    "save_folder = \"analysis_output\"\n",
    "map_execution(file_path, save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\audio.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\video.py\n",
      "Skipping already analyzed file: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Skipping already analyzed file: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\vision_v2.py\n",
      "Skipping already analyzed file: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Skipping already analyzed file: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\audio.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\constants.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\audio_v2.py\n",
      "Skipping already analyzed file: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Skipping already analyzed file: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Skipping already analyzed file: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\audio.py\n",
      "Skipping already analyzed file: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\video.py\n",
      "Skipping already analyzed file: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\talknet.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\video_v2.py\n",
      "Skipping already analyzed file: C:\\Users\\justl\\Documents\\VideoDiarization\\talknet.py\n",
      "Skipping already analyzed file: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\utils.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\main_v3.py\n",
      "Execution map complete. Results saved to analysis_output\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "from typing import List, Optional, Dict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Alias(BaseModel):\n",
    "    actual_name: str\n",
    "    alias_name: str\n",
    "    local_file: bool\n",
    "\n",
    "class Node(BaseModel):\n",
    "    type: str\n",
    "    content: str\n",
    "    children: List['Node'] = []\n",
    "    function: Optional[str] = None\n",
    "    alias: Optional[Alias] = None\n",
    "    line_number: Optional[int] = None\n",
    "    end_line_number: Optional[int] = None\n",
    "    docstring: Optional[str] = None\n",
    "    return_type: Optional[str] = None\n",
    "\n",
    "class PyFileAnalyzer(ast.NodeVisitor):\n",
    "    def __init__(self, source_code, file_path, save_folder):\n",
    "        self.root = Node(type=\"module\", content=\"\", children=[])\n",
    "        self.current_node = self.root\n",
    "        self.save_folder = save_folder\n",
    "        self.file_path = file_path\n",
    "        self.folder_path = os.path.dirname(file_path)\n",
    "        self.source_code = source_code.splitlines()\n",
    "        self.alias_dict = {}\n",
    "        self.variable_types = {}\n",
    "\n",
    "    def get_node_content(self, node):\n",
    "        start_line = node.lineno - 1\n",
    "        end_line = node.end_lineno\n",
    "        content = ' '.join(self.source_code[start_line:end_line]).strip()\n",
    "        return content\n",
    "\n",
    "    def visit_Import(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        for alias in node.names:\n",
    "            tmp_local_file_path = alias.name.replace('.', os.path.sep) + \".py\"\n",
    "            tmp_abs_file_path = os.path.join(self.folder_path, tmp_local_file_path)\n",
    "\n",
    "            local_file = os.path.exists(tmp_abs_file_path)\n",
    "\n",
    "            if local_file:\n",
    "                analyze_python_file(tmp_abs_file_path, self.save_folder)\n",
    "\n",
    "            new_alias = Alias(actual_name=alias.name, alias_name=alias.asname or alias.name, local_file=local_file)\n",
    "            self.alias_dict[alias.asname or alias.name] = new_alias\n",
    "\n",
    "            import_node = Node(\n",
    "                type=\"import\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                alias=new_alias\n",
    "            )\n",
    "            self.current_node.children.append(import_node)\n",
    "\n",
    "    def visit_ImportFrom(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        module = node.module or \"\"\n",
    "        \n",
    "        tmp_local_file_path = module.replace('.', os.path.sep) + \".py\"\n",
    "        tmp_abs_file_path = os.path.join(self.folder_path, tmp_local_file_path)\n",
    "\n",
    "        local_file = os.path.exists(tmp_abs_file_path)\n",
    "\n",
    "        if local_file:\n",
    "            analyze_python_file(tmp_abs_file_path, self.save_folder)\n",
    "\n",
    "        for alias in node.names:\n",
    "            new_alias = Alias(\n",
    "                actual_name=f\"{module}.{alias.name}\", \n",
    "                alias_name=alias.asname or alias.name, \n",
    "                local_file=local_file\n",
    "            )\n",
    "            self.alias_dict[alias.asname or alias.name] = new_alias\n",
    "\n",
    "            import_node = Node(\n",
    "                type=\"import\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                alias=new_alias\n",
    "            )\n",
    "            self.current_node.children.append(import_node)\n",
    "\n",
    "    def visit_AnnAssign(self, node):\n",
    "        if isinstance(node.target, ast.Name) and isinstance(node.annotation, ast.Name):\n",
    "            var_name = node.target.id\n",
    "            type_name = node.annotation.id\n",
    "            if type_name in self.alias_dict:\n",
    "                self.variable_types[var_name] = self.alias_dict[type_name].actual_name\n",
    "\n",
    "    def visit_Call(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        if isinstance(node.func, ast.Name):\n",
    "            function_name = node.func.id\n",
    "            if function_name in self.alias_dict:\n",
    "                function_name = self.alias_dict[function_name].actual_name\n",
    "            call_node = Node(\n",
    "                type=\"function_call\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                function=function_name\n",
    "            )\n",
    "            self.current_node.children.append(call_node)\n",
    "        elif isinstance(node.func, ast.Attribute):\n",
    "            full_name = self.get_full_attribute_name(node.func)\n",
    "            parts = full_name.split('.')\n",
    "            if parts[0] in self.variable_types:\n",
    "                parts[0] = self.variable_types[parts[0]]\n",
    "            function_name = '.'.join(parts)\n",
    "            call_node = Node(\n",
    "                type=\"function_call\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                function=function_name\n",
    "            )\n",
    "            self.current_node.children.append(call_node)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def get_full_attribute_name(self, node):\n",
    "        if isinstance(node.value, ast.Name):\n",
    "            return f\"{node.value.id}.{node.attr}\"\n",
    "        elif isinstance(node.value, ast.Attribute):\n",
    "            return f\"{self.get_full_attribute_name(node.value)}.{node.attr}\"\n",
    "        return node.attr\n",
    "\n",
    "def analyze_python_file(file_path: str, save_folder: str) -> Node:\n",
    "    file_path = os.path.abspath(file_path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_name = os.path.splitext(file_path)[0]\n",
    "    json_path = os.path.join(save_folder, f\"{file_name}.json\")\n",
    "\n",
    "    # Check if the file has already been analyzed\n",
    "    if os.path.exists(json_path):\n",
    "        print(f\"Skipping already analyzed file: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            source_code = file.read()\n",
    "            tree = ast.parse(source_code, filename=file_path)\n",
    "        \n",
    "        analyzer = PyFileAnalyzer(source_code, file_path, save_folder)\n",
    "        analyzer.visit(tree)\n",
    "\n",
    "        root_node = analyzer.root\n",
    "\n",
    "        json_output = json.dumps(node_to_dict(root_node), indent=2)\n",
    "\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json_file.write(json_output)\n",
    "\n",
    "        print(f\"Analyzed and saved JSON for: {file_path}\")\n",
    "        return analyzer.root\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing file {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def node_to_dict(node: Node) -> dict:\n",
    "    result = {\n",
    "        \"type\": node.type,\n",
    "        \"content\": node.content,\n",
    "        \"children\": [node_to_dict(child) for child in node.children],\n",
    "        \"line_number\": node.line_number,\n",
    "        \"end_line_number\": node.end_line_number\n",
    "    }\n",
    "    if node.function:\n",
    "        result[\"function\"] = node.function\n",
    "    if node.alias:\n",
    "        result[\"alias\"] = node.alias.dict()\n",
    "    if node.docstring:\n",
    "        result[\"docstring\"] = node.docstring\n",
    "    if node.return_type:\n",
    "        result[\"return_type\"] = node.return_type\n",
    "    return result\n",
    "\n",
    "def map_execution(file_path: str, save_folder: str):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    analyze_python_file(file_path, save_folder)\n",
    "\n",
    "    print(f\"Execution map complete. Results saved to {save_folder}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"C:/Users/justl/Documents/VideoDiarization/main_v3.py\"\n",
    "save_folder = \"analysis_output\"\n",
    "map_execution(file_path, save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\audio.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\video.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\vision_v2.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\audio.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\constants.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\audio_v2.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\audio.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\video.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\talknet.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\video_v2.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\talknet.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\utils.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\main_v3.py\n",
      "Execution map complete. Results saved to analysis_output\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import importlib\n",
    "import os\n",
    "from typing import List, Optional, Dict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Alias(BaseModel):\n",
    "    actual_name: str\n",
    "    alias_name: str\n",
    "    local_file: bool\n",
    "\n",
    "class Node(BaseModel):\n",
    "    type: str\n",
    "    content: str\n",
    "    children: List['Node'] = []\n",
    "    function: Optional[str] = None\n",
    "    alias: Optional[Alias] = None\n",
    "    line_number: Optional[int] = None\n",
    "    end_line_number: Optional[int] = None\n",
    "    docstring: Optional[str] = None\n",
    "    return_type: Optional[str] = None\n",
    "\n",
    "class PyFileAnalyzer(ast.NodeVisitor):\n",
    "    def __init__(self, source_code, file_path, save_folder):\n",
    "        self.root = Node(type=\"module\", content=\"\", children=[])\n",
    "        self.current_node = self.root\n",
    "        self.save_folder = save_folder\n",
    "        self.file_path = file_path\n",
    "        self.folder_path = os.path.dirname(file_path)\n",
    "        self.source_code = source_code.splitlines()\n",
    "        self.alias_dict = {}\n",
    "        self.variable_types = {}\n",
    "        self.analyzed_files = set()\n",
    "\n",
    "    def get_node_content(self, node):\n",
    "        start_line = node.lineno - 1\n",
    "        end_line = node.end_lineno\n",
    "        content = ' '.join(self.source_code[start_line:end_line]).strip()\n",
    "        return content\n",
    "\n",
    "    def visit_Import(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        for alias in node.names:\n",
    "            tmp_local_file_path = alias.name.replace('.', os.path.sep) + \".py\"\n",
    "            tmp_abs_file_path = os.path.join(self.folder_path, tmp_local_file_path)\n",
    "\n",
    "            local_file = os.path.exists(tmp_abs_file_path)\n",
    "\n",
    "            if local_file and tmp_abs_file_path not in self.analyzed_files:\n",
    "                self.analyzed_files.add(tmp_abs_file_path)\n",
    "                analyze_python_file(tmp_abs_file_path, self.save_folder)\n",
    "\n",
    "            new_alias = Alias(actual_name=alias.name, alias_name=alias.asname or alias.name, local_file=local_file)\n",
    "            self.alias_dict[alias.asname or alias.name] = new_alias\n",
    "\n",
    "            import_node = Node(\n",
    "                type=\"import\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                alias=new_alias\n",
    "            )\n",
    "            self.current_node.children.append(import_node)\n",
    "\n",
    "    def visit_ImportFrom(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        module = node.module or \"\"\n",
    "        \n",
    "        tmp_local_file_path = module.replace('.', os.path.sep) + \".py\"\n",
    "        tmp_abs_file_path = os.path.join(self.folder_path, tmp_local_file_path)\n",
    "\n",
    "        local_file = os.path.exists(tmp_abs_file_path)\n",
    "\n",
    "        if local_file and tmp_abs_file_path not in self.analyzed_files:\n",
    "            self.analyzed_files.add(tmp_abs_file_path)\n",
    "            analyze_python_file(tmp_abs_file_path, self.save_folder)\n",
    "\n",
    "        if len(node.names) == 1 and node.names[0].name == '*':\n",
    "            # Handle star import\n",
    "            self.handle_star_import(module, tmp_abs_file_path if local_file else None)\n",
    "        else:\n",
    "            for alias in node.names:\n",
    "                new_alias = Alias(\n",
    "                    actual_name=f\"{module}.{alias.name}\", \n",
    "                    alias_name=alias.asname or alias.name, \n",
    "                    local_file=local_file\n",
    "                )\n",
    "                self.alias_dict[alias.asname or alias.name] = new_alias\n",
    "\n",
    "                import_node = Node(\n",
    "                    type=\"import\",\n",
    "                    content=content,\n",
    "                    line_number=node.lineno,\n",
    "                    alias=new_alias\n",
    "                )\n",
    "                self.current_node.children.append(import_node)\n",
    "\n",
    "    def handle_star_import(self, module_name, module_path):\n",
    "        if module_path:\n",
    "            # For local modules\n",
    "            with open(module_path, 'r') as file:\n",
    "                module_ast = ast.parse(file.read())\n",
    "            names = self.get_module_names(module_ast)\n",
    "        else:\n",
    "            # For non-local modules\n",
    "            try:\n",
    "                module = importlib.import_module(module_name)\n",
    "                names = dir(module)\n",
    "            except ImportError:\n",
    "                print(f\"Warning: Unable to import module {module_name}\")\n",
    "                return\n",
    "\n",
    "        for name in names:\n",
    "            if not name.startswith('_'):  # Exclude private names\n",
    "                new_alias = Alias(\n",
    "                    actual_name=f\"{module_name}.{name}\",\n",
    "                    alias_name=name,\n",
    "                    local_file=bool(module_path)\n",
    "                )\n",
    "                self.alias_dict[name] = new_alias\n",
    "\n",
    "    def get_module_names(self, module_ast):\n",
    "        names = []\n",
    "        for node in module_ast.body:\n",
    "            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n",
    "                names.append(node.name)\n",
    "        return names\n",
    "\n",
    "    def visit_AnnAssign(self, node):\n",
    "        if isinstance(node.target, ast.Name) and isinstance(node.annotation, ast.Name):\n",
    "            var_name = node.target.id\n",
    "            type_name = node.annotation.id\n",
    "            if type_name in self.alias_dict:\n",
    "                self.variable_types[var_name] = self.alias_dict[type_name].actual_name\n",
    "\n",
    "    def visit_Call(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        if isinstance(node.func, ast.Name):\n",
    "            function_name = node.func.id\n",
    "            if function_name in self.alias_dict:\n",
    "                function_name = self.alias_dict[function_name].actual_name\n",
    "            call_node = Node(\n",
    "                type=\"function_call\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                function=function_name\n",
    "            )\n",
    "            self.current_node.children.append(call_node)\n",
    "        elif isinstance(node.func, ast.Attribute):\n",
    "            full_name = self.get_full_attribute_name(node.func)\n",
    "            parts = full_name.split('.')\n",
    "            if parts[0] in self.variable_types:\n",
    "                parts[0] = self.variable_types[parts[0]]\n",
    "            function_name = '.'.join(parts)\n",
    "            call_node = Node(\n",
    "                type=\"function_call\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                function=function_name\n",
    "            )\n",
    "            self.current_node.children.append(call_node)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def get_full_attribute_name(self, node):\n",
    "        if isinstance(node.value, ast.Name):\n",
    "            return f\"{node.value.id}.{node.attr}\"\n",
    "        elif isinstance(node.value, ast.Attribute):\n",
    "            return f\"{self.get_full_attribute_name(node.value)}.{node.attr}\"\n",
    "        return node.attr\n",
    "\n",
    "def analyze_python_file(file_path: str, save_folder: str) -> Node:\n",
    "    file_path = os.path.abspath(file_path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    json_path = os.path.join(save_folder, f\"{file_name}.json\")\n",
    "\n",
    "    # Check if the file has already been analyzed\n",
    "    # if os.path.exists(json_path):\n",
    "    #     print(f\"Skipping already analyzed file: {file_path}\")\n",
    "    #     return None\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            source_code = file.read()\n",
    "            tree = ast.parse(source_code, filename=file_path)\n",
    "        \n",
    "        analyzer = PyFileAnalyzer(source_code, file_path, save_folder)\n",
    "        analyzer.visit(tree)\n",
    "\n",
    "        root_node = analyzer.root\n",
    "\n",
    "        json_output = json.dumps(node_to_dict(root_node), indent=2)\n",
    "\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json_file.write(json_output)\n",
    "\n",
    "        print(f\"Analyzed and saved JSON for: {file_path}\")\n",
    "        return analyzer.root\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing file {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def node_to_dict(node: Node) -> dict:\n",
    "    result = {\n",
    "        \"type\": node.type,\n",
    "        \"content\": node.content,\n",
    "        \"children\": [node_to_dict(child) for child in node.children],\n",
    "        \"line_number\": node.line_number,\n",
    "        \"end_line_number\": node.end_line_number\n",
    "    }\n",
    "    if node.function:\n",
    "        result[\"function\"] = node.function\n",
    "    if node.alias:\n",
    "        result[\"alias\"] = node.alias.dict()\n",
    "    if node.docstring:\n",
    "        result[\"docstring\"] = node.docstring\n",
    "    if node.return_type:\n",
    "        result[\"return_type\"] = node.return_type\n",
    "    return result\n",
    "\n",
    "def map_execution(file_path: str, save_folder: str):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    analyze_python_file(file_path, save_folder)\n",
    "\n",
    "    print(f\"Execution map complete. Results saved to {save_folder}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"C:/Users/justl/Documents/VideoDiarization/main_v3.py\"  # Replace with your actual Python file path\n",
    "save_folder = \"analysis_output\"\n",
    "map_execution(file_path, save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\audio.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\video.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Error analyzing file C:\\Users\\justl\\Documents\\VideoDiarization\\vision_v2.py: list index out of range\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\audio.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\constants.py\n",
      "Error analyzing file C:\\Users\\justl\\Documents\\VideoDiarization\\audio_v2.py: list index out of range\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\audio.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\video.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\talknet.py\n",
      "Error analyzing file C:\\Users\\justl\\Documents\\VideoDiarization\\video_v2.py: list index out of range\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\talknet.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\utils.py\n",
      "Error analyzing file C:\\Users\\justl\\Documents\\VideoDiarization\\main_v3.py: list index out of range\n",
      "Execution map complete. Results saved to analysis_output\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "import importlib\n",
    "import os\n",
    "from typing import List, Optional, Dict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Alias(BaseModel):\n",
    "    actual_name: str\n",
    "    alias_name: str\n",
    "    local_file: bool\n",
    "\n",
    "class Node(BaseModel):\n",
    "    type: str\n",
    "    content: str\n",
    "    children: List['Node'] = []\n",
    "    function: Optional[str] = None\n",
    "    alias: Optional[Alias] = None\n",
    "    line_number: Optional[int] = None\n",
    "    end_line_number: Optional[int] = None\n",
    "    docstring: Optional[str] = None\n",
    "    return_type: Optional[str] = None\n",
    "    indent_level: int = 0\n",
    "\n",
    "class PyFileAnalyzer(ast.NodeVisitor):\n",
    "    def __init__(self, source_code, file_path, save_folder):\n",
    "        self.root = Node(type=\"module\", content=\"\", children=[])\n",
    "        self.current_node = self.root\n",
    "        self.save_folder = save_folder\n",
    "        self.file_path = file_path\n",
    "        self.folder_path = os.path.dirname(file_path)\n",
    "        self.source_code = source_code.splitlines()\n",
    "        self.alias_dict = {}\n",
    "        self.variable_types = {}\n",
    "        self.analyzed_files = set()\n",
    "        self.indent_level = 0\n",
    "\n",
    "    def get_node_content(self, node):\n",
    "        start_line = node.lineno - 1\n",
    "        end_line = node.end_lineno\n",
    "        content = '\\n'.join(self.source_code[start_line:end_line]).strip()\n",
    "        return content\n",
    "\n",
    "    def visit_Import(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        for alias in node.names:\n",
    "            tmp_local_file_path = alias.name.replace('.', os.path.sep) + \".py\"\n",
    "            tmp_abs_file_path = os.path.join(self.folder_path, tmp_local_file_path)\n",
    "\n",
    "            local_file = os.path.exists(tmp_abs_file_path)\n",
    "\n",
    "            if local_file and tmp_abs_file_path not in self.analyzed_files:\n",
    "                self.analyzed_files.add(tmp_abs_file_path)\n",
    "                analyze_python_file(tmp_abs_file_path, self.save_folder)\n",
    "\n",
    "            new_alias = Alias(actual_name=alias.name, alias_name=alias.asname or alias.name, local_file=local_file)\n",
    "            self.alias_dict[alias.asname or alias.name] = new_alias\n",
    "\n",
    "            import_node = Node(\n",
    "                type=\"import\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                end_line_number=node.end_lineno,\n",
    "                alias=new_alias,\n",
    "                indent_level=self.indent_level\n",
    "            )\n",
    "            self.current_node.children.append(import_node)\n",
    "\n",
    "    def visit_ImportFrom(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        module = node.module or \"\"\n",
    "        \n",
    "        tmp_local_file_path = module.replace('.', os.path.sep) + \".py\"\n",
    "        tmp_abs_file_path = os.path.join(self.folder_path, tmp_local_file_path)\n",
    "\n",
    "        local_file = os.path.exists(tmp_abs_file_path)\n",
    "\n",
    "        if local_file and tmp_abs_file_path not in self.analyzed_files:\n",
    "            self.analyzed_files.add(tmp_abs_file_path)\n",
    "            analyze_python_file(tmp_abs_file_path, self.save_folder)\n",
    "\n",
    "        if len(node.names) == 1 and node.names[0].name == '*':\n",
    "            self.handle_star_import(module, tmp_abs_file_path if local_file else None)\n",
    "        else:\n",
    "            for alias in node.names:\n",
    "                new_alias = Alias(\n",
    "                    actual_name=f\"{module}.{alias.name}\", \n",
    "                    alias_name=alias.asname or alias.name, \n",
    "                    local_file=local_file\n",
    "                )\n",
    "                self.alias_dict[alias.asname or alias.name] = new_alias\n",
    "\n",
    "                import_node = Node(\n",
    "                    type=\"import\",\n",
    "                    content=content,\n",
    "                    line_number=node.lineno,\n",
    "                    end_line_number=node.end_lineno,\n",
    "                    alias=new_alias,\n",
    "                    indent_level=self.indent_level\n",
    "                )\n",
    "                self.current_node.children.append(import_node)\n",
    "\n",
    "    def handle_star_import(self, module_name, module_path):\n",
    "        if module_path:\n",
    "            with open(module_path, 'r') as file:\n",
    "                module_ast = ast.parse(file.read())\n",
    "            names = self.get_module_names(module_ast)\n",
    "        else:\n",
    "            try:\n",
    "                module = importlib.import_module(module_name)\n",
    "                names = dir(module)\n",
    "            except ImportError:\n",
    "                print(f\"Warning: Unable to import module {module_name}\")\n",
    "                return\n",
    "\n",
    "        for name in names:\n",
    "            if not name.startswith('_'):\n",
    "                new_alias = Alias(\n",
    "                    actual_name=f\"{module_name}.{name}\",\n",
    "                    alias_name=name,\n",
    "                    local_file=bool(module_path)\n",
    "                )\n",
    "                self.alias_dict[name] = new_alias\n",
    "\n",
    "    def get_module_names(self, module_ast):\n",
    "        names = []\n",
    "        for node in module_ast.body:\n",
    "            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n",
    "                names.append(node.name)\n",
    "        return names\n",
    "\n",
    "    def visit_AnnAssign(self, node):\n",
    "        if isinstance(node.target, ast.Name) and isinstance(node.annotation, ast.Name):\n",
    "            var_name = node.target.id\n",
    "            type_name = node.annotation.id\n",
    "            if type_name in self.alias_dict:\n",
    "                self.variable_types[var_name] = self.alias_dict[type_name].actual_name\n",
    "\n",
    "    def visit_Call(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        if isinstance(node.func, ast.Name):\n",
    "            function_name = node.func.id\n",
    "            if function_name in self.alias_dict:\n",
    "                function_name = self.alias_dict[function_name].actual_name\n",
    "            call_node = Node(\n",
    "                type=\"function_call\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                end_line_number=node.end_lineno,\n",
    "                function=function_name,\n",
    "                indent_level=self.indent_level\n",
    "            )\n",
    "            self.current_node.children.append(call_node)\n",
    "        elif isinstance(node.func, ast.Attribute):\n",
    "            full_name = self.get_full_attribute_name(node.func)\n",
    "            parts = full_name.split('.')\n",
    "            if parts[0] in self.variable_types:\n",
    "                parts[0] = self.variable_types[parts[0]]\n",
    "            function_name = '.'.join(parts)\n",
    "            call_node = Node(\n",
    "                type=\"function_call\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                end_line_number=node.end_lineno,\n",
    "                function=function_name,\n",
    "                indent_level=self.indent_level\n",
    "            )\n",
    "            self.current_node.children.append(call_node)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def get_full_attribute_name(self, node):\n",
    "        if isinstance(node.value, ast.Name):\n",
    "            return f\"{node.value.id}.{node.attr}\"\n",
    "        elif isinstance(node.value, ast.Attribute):\n",
    "            return f\"{self.get_full_attribute_name(node.value)}.{node.attr}\"\n",
    "        return node.attr\n",
    "\n",
    "    def visit_For(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        for_node = Node(\n",
    "            type=\"for\",\n",
    "            content=content,\n",
    "            line_number=node.lineno,\n",
    "            end_line_number=node.end_lineno,\n",
    "            indent_level=self.indent_level\n",
    "        )\n",
    "        self.current_node.children.append(for_node)\n",
    "        self.current_node = for_node\n",
    "        self.indent_level += 1\n",
    "        self.generic_visit(node)\n",
    "        self.indent_level -= 1\n",
    "        self.current_node = self.current_node.children[-1]\n",
    "\n",
    "    def visit_While(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        while_node = Node(\n",
    "            type=\"while\",\n",
    "            content=content,\n",
    "            line_number=node.lineno,\n",
    "            end_line_number=node.end_lineno,\n",
    "            indent_level=self.indent_level\n",
    "        )\n",
    "        self.current_node.children.append(while_node)\n",
    "        self.current_node = while_node\n",
    "        self.indent_level += 1\n",
    "        self.generic_visit(node)\n",
    "        self.indent_level -= 1\n",
    "        self.current_node = self.current_node.children[-1]\n",
    "\n",
    "    def visit_If(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        if_node = Node(\n",
    "            type=\"if\",\n",
    "            content=content,\n",
    "            line_number=node.lineno,\n",
    "            end_line_number=node.end_lineno,\n",
    "            indent_level=self.indent_level\n",
    "        )\n",
    "        self.current_node.children.append(if_node)\n",
    "        self.current_node = if_node\n",
    "        self.indent_level += 1\n",
    "        self.generic_visit(node)\n",
    "        self.indent_level -= 1\n",
    "        self.current_node = self.current_node.children[-1]\n",
    "\n",
    "def analyze_python_file(file_path: str, save_folder: str) -> Node:\n",
    "    file_path = os.path.abspath(file_path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    json_path = os.path.join(save_folder, f\"{file_name}.json\")\n",
    "\n",
    "    # if os.path.exists(json_path):\n",
    "    #     print(f\"Skipping already analyzed file: {file_path}\")\n",
    "    #     return None\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            source_code = file.read()\n",
    "            tree = ast.parse(source_code, filename=file_path)\n",
    "        \n",
    "        analyzer = PyFileAnalyzer(source_code, file_path, save_folder)\n",
    "        analyzer.visit(tree)\n",
    "\n",
    "        root_node = analyzer.root\n",
    "\n",
    "        json_output = json.dumps(node_to_dict(root_node), indent=2)\n",
    "\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json_file.write(json_output)\n",
    "\n",
    "        print(f\"Analyzed and saved JSON for: {file_path}\")\n",
    "        return analyzer.root\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing file {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def node_to_dict(node: Node) -> dict:\n",
    "    result = {\n",
    "        \"type\": node.type,\n",
    "        \"content\": node.content,\n",
    "        \"children\": [node_to_dict(child) for child in node.children],\n",
    "        \"line_number\": node.line_number,\n",
    "        \"end_line_number\": node.end_line_number,\n",
    "        \"indent_level\": node.indent_level\n",
    "    }\n",
    "    if node.function:\n",
    "        result[\"function\"] = node.function\n",
    "    if node.alias:\n",
    "        result[\"alias\"] = node.alias.dict()\n",
    "    if node.docstring:\n",
    "        result[\"docstring\"] = node.docstring\n",
    "    if node.return_type:\n",
    "        result[\"return_type\"] = node.return_type\n",
    "    return result\n",
    "\n",
    "def map_execution(file_path: str, save_folder: str):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    analyze_python_file(file_path, save_folder)\n",
    "\n",
    "    print(f\"Execution map complete. Results saved to {save_folder}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"C:/Users/justl/Documents/VideoDiarization/main_v3.py\"  # Replace with your actual Python file path\n",
    "save_folder = \"analysis_output\"\n",
    "map_execution(file_path, save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\audio.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\video.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Error analyzing file C:\\Users\\justl\\Documents\\VideoDiarization\\vision_v2.py: list index out of range\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\audio.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\constants.py\n",
      "Error analyzing file C:\\Users\\justl\\Documents\\VideoDiarization\\audio_v2.py: list index out of range\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\audio.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\video.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\talknet.py\n",
      "Error analyzing file C:\\Users\\justl\\Documents\\VideoDiarization\\video_v2.py: list index out of range\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\vision.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\talknet.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\custom_types\\config.py\n",
      "Analyzed and saved JSON for: C:\\Users\\justl\\Documents\\VideoDiarization\\utils.py\n",
      "Error analyzing file C:\\Users\\justl\\Documents\\VideoDiarization\\main_v3.py: list index out of range\n",
      "Execution map complete. Results saved to analysis_output\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "import importlib\n",
    "import os\n",
    "from typing import List, Optional, Dict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Alias(BaseModel):\n",
    "    actual_name: str\n",
    "    alias_name: str\n",
    "    local_file: bool\n",
    "\n",
    "class Node(BaseModel):\n",
    "    type: str\n",
    "    content: str\n",
    "    children: List['Node'] = []\n",
    "    function: Optional[str] = None\n",
    "    alias: Optional[Alias] = None\n",
    "    line_number: Optional[int] = None\n",
    "    end_line_number: Optional[int] = None\n",
    "    docstring: Optional[str] = None\n",
    "    return_type: Optional[str] = None\n",
    "    indent_level: int = 0\n",
    "\n",
    "class PyFileAnalyzer(ast.NodeVisitor):\n",
    "    def __init__(self, source_code, file_path, save_folder, global_function_defs):\n",
    "        self.root = Node(type=\"module\", content=\"\", children=[])\n",
    "        self.current_node = self.root\n",
    "        self.save_folder = save_folder\n",
    "        self.file_path = file_path\n",
    "        self.folder_path = os.path.dirname(file_path)\n",
    "        self.source_code = source_code.splitlines()\n",
    "        self.alias_dict = {}\n",
    "        self.variable_types = {}\n",
    "        self.analyzed_files = set()\n",
    "        self.indent_level = 0\n",
    "        self.function_defs = {}\n",
    "        self.current_function_stack = []\n",
    "        self.global_function_defs = global_function_defs\n",
    "\n",
    "    def get_node_content(self, node):\n",
    "        start_line = node.lineno - 1\n",
    "        end_line = node.end_lineno\n",
    "        content = '\\n'.join(self.source_code[start_line:end_line]).strip()\n",
    "        return content\n",
    "\n",
    "    def visit_Import(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        for alias in node.names:\n",
    "            tmp_local_file_path = alias.name.replace('.', os.path.sep) + \".py\"\n",
    "            tmp_abs_file_path = os.path.join(self.folder_path, tmp_local_file_path)\n",
    "\n",
    "            local_file = os.path.exists(tmp_abs_file_path)\n",
    "\n",
    "            if local_file and tmp_abs_file_path not in self.analyzed_files:\n",
    "                self.analyzed_files.add(tmp_abs_file_path)\n",
    "                analyze_python_file(tmp_abs_file_path, self.save_folder, self.global_function_defs)\n",
    "\n",
    "            new_alias = Alias(actual_name=alias.name, alias_name=alias.asname or alias.name, local_file=local_file)\n",
    "            self.alias_dict[alias.asname or alias.name] = new_alias\n",
    "\n",
    "            import_node = Node(\n",
    "                type=\"import\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                end_line_number=node.end_lineno,\n",
    "                alias=new_alias,\n",
    "                indent_level=self.indent_level\n",
    "            )\n",
    "            self.current_node.children.append(import_node)\n",
    "\n",
    "    def visit_ImportFrom(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        module = node.module or \"\"\n",
    "        \n",
    "        tmp_local_file_path = module.replace('.', os.path.sep) + \".py\"\n",
    "        tmp_abs_file_path = os.path.join(self.folder_path, tmp_local_file_path)\n",
    "\n",
    "        local_file = os.path.exists(tmp_abs_file_path)\n",
    "\n",
    "        if local_file and tmp_abs_file_path not in self.analyzed_files:\n",
    "            self.analyzed_files.add(tmp_abs_file_path)\n",
    "            analyze_python_file(tmp_abs_file_path, self.save_folder, self.global_function_defs)\n",
    "\n",
    "        if len(node.names) == 1 and node.names[0].name == '*':\n",
    "            self.handle_star_import(module, tmp_abs_file_path if local_file else None)\n",
    "        else:\n",
    "            for alias in node.names:\n",
    "                new_alias = Alias(\n",
    "                    actual_name=f\"{module}.{alias.name}\", \n",
    "                    alias_name=alias.asname or alias.name, \n",
    "                    local_file=local_file\n",
    "                )\n",
    "                self.alias_dict[alias.asname or alias.name] = new_alias\n",
    "\n",
    "                import_node = Node(\n",
    "                    type=\"import\",\n",
    "                    content=content,\n",
    "                    line_number=node.lineno,\n",
    "                    end_line_number=node.end_lineno,\n",
    "                    alias=new_alias,\n",
    "                    indent_level=self.indent_level\n",
    "                )\n",
    "                self.current_node.children.append(import_node)\n",
    "\n",
    "    def handle_star_import(self, module_name, module_path):\n",
    "        if module_path:\n",
    "            with open(module_path, 'r') as file:\n",
    "                module_ast = ast.parse(file.read())\n",
    "            names = self.get_module_names(module_ast)\n",
    "        else:\n",
    "            try:\n",
    "                module = importlib.import_module(module_name)\n",
    "                names = dir(module)\n",
    "            except ImportError:\n",
    "                print(f\"Warning: Unable to import module {module_name}\")\n",
    "                return\n",
    "\n",
    "        for name in names:\n",
    "            if not name.startswith('_'):\n",
    "                new_alias = Alias(\n",
    "                    actual_name=f\"{module_name}.{name}\",\n",
    "                    alias_name=name,\n",
    "                    local_file=bool(module_path)\n",
    "                )\n",
    "                self.alias_dict[name] = new_alias\n",
    "\n",
    "    def get_module_names(self, module_ast):\n",
    "        names = []\n",
    "        for node in module_ast.body:\n",
    "            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n",
    "                names.append(node.name)\n",
    "        return names\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        func_node = Node(\n",
    "            type=\"function_def\",\n",
    "            content=content,\n",
    "            line_number=node.lineno,\n",
    "            end_line_number=node.end_lineno,\n",
    "            function=node.name,\n",
    "            indent_level=self.indent_level,\n",
    "            docstring=ast.get_docstring(node)\n",
    "        )\n",
    "        self.function_defs[node.name] = func_node\n",
    "        self.global_function_defs[f\"{os.path.basename(self.file_path)}:{node.name}\"] = func_node\n",
    "        self.current_node.children.append(func_node)\n",
    "        \n",
    "        old_node = self.current_node\n",
    "        self.current_node = func_node\n",
    "        self.indent_level += 1\n",
    "        self.current_function_stack.append(node.name)\n",
    "        self.generic_visit(node)\n",
    "        self.current_function_stack.pop()\n",
    "        self.indent_level -= 1\n",
    "        self.current_node = old_node\n",
    "\n",
    "    def visit_AnnAssign(self, node):\n",
    "        if isinstance(node.target, ast.Name) and isinstance(node.annotation, ast.Name):\n",
    "            var_name = node.target.id\n",
    "            type_name = node.annotation.id\n",
    "            if type_name in self.alias_dict:\n",
    "                self.variable_types[var_name] = self.alias_dict[type_name].actual_name\n",
    "\n",
    "    def visit_Call(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        if isinstance(node.func, ast.Name):\n",
    "            function_name = node.func.id\n",
    "            if function_name in self.alias_dict:\n",
    "                function_name = self.alias_dict[function_name].actual_name\n",
    "        elif isinstance(node.func, ast.Attribute):\n",
    "            full_name = self.get_full_attribute_name(node.func)\n",
    "            parts = full_name.split('.')\n",
    "            if parts[0] in self.variable_types:\n",
    "                parts[0] = self.variable_types[parts[0]]\n",
    "            function_name = '.'.join(parts)\n",
    "        else:\n",
    "            function_name = \"unknown\"\n",
    "\n",
    "        call_node = Node(\n",
    "            type=\"function_call\",\n",
    "            content=content,\n",
    "            line_number=node.lineno,\n",
    "            end_line_number=node.end_lineno,\n",
    "            function=function_name,\n",
    "            indent_level=self.indent_level\n",
    "        )\n",
    "        self.current_node.children.append(call_node)\n",
    "\n",
    "        for full_func_name, func_def in self.global_function_defs.items():\n",
    "            if full_func_name.endswith(f\":{function_name.split('.')[-1]}\") and function_name not in self.current_function_stack:\n",
    "                func_def_copy = func_def.copy(deep=True)\n",
    "                func_def_copy.indent_level = self.indent_level + 1\n",
    "                call_node.children.append(func_def_copy)\n",
    "                break\n",
    "\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def get_full_attribute_name(self, node):\n",
    "        if isinstance(node.value, ast.Name):\n",
    "            return f\"{node.value.id}.{node.attr}\"\n",
    "        elif isinstance(node.value, ast.Attribute):\n",
    "            return f\"{self.get_full_attribute_name(node.value)}.{node.attr}\"\n",
    "        return node.attr\n",
    "\n",
    "    def visit_For(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        for_node = Node(\n",
    "            type=\"for\",\n",
    "            content=content,\n",
    "            line_number=node.lineno,\n",
    "            end_line_number=node.end_lineno,\n",
    "            indent_level=self.indent_level\n",
    "        )\n",
    "        self.current_node.children.append(for_node)\n",
    "        self.current_node = for_node\n",
    "        self.indent_level += 1\n",
    "        self.generic_visit(node)\n",
    "        self.indent_level -= 1\n",
    "        self.current_node = self.current_node.children[-1]\n",
    "\n",
    "    def visit_While(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        while_node = Node(\n",
    "            type=\"while\",\n",
    "            content=content,\n",
    "            line_number=node.lineno,\n",
    "            end_line_number=node.end_lineno,\n",
    "            indent_level=self.indent_level\n",
    "        )\n",
    "        self.current_node.children.append(while_node)\n",
    "        self.current_node = while_node\n",
    "        self.indent_level += 1\n",
    "        self.generic_visit(node)\n",
    "        self.indent_level -= 1\n",
    "        self.current_node = self.current_node.children[-1]\n",
    "\n",
    "    def visit_If(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        if_node = Node(\n",
    "            type=\"if\",\n",
    "            content=content,\n",
    "            line_number=node.lineno,\n",
    "            end_line_number=node.end_lineno,\n",
    "            indent_level=self.indent_level\n",
    "        )\n",
    "        self.current_node.children.append(if_node)\n",
    "        self.current_node = if_node\n",
    "        self.indent_level += 1\n",
    "        self.generic_visit(node)\n",
    "        self.indent_level -= 1\n",
    "        self.current_node = self.current_node.children[-1]\n",
    "\n",
    "def analyze_python_file(file_path: str, save_folder: str, global_function_defs: Dict[str, Node]) -> Node:\n",
    "    file_path = os.path.abspath(file_path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    json_path = os.path.join(save_folder, f\"{file_name}.json\")\n",
    "\n",
    "    # if os.path.exists(json_path):\n",
    "    #     print(f\"Skipping already analyzed file: {file_path}\")\n",
    "    #     return None\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            source_code = file.read()\n",
    "            tree = ast.parse(source_code, filename=file_path)\n",
    "        \n",
    "        analyzer = PyFileAnalyzer(source_code, file_path, save_folder, global_function_defs)\n",
    "        analyzer.visit(tree)\n",
    "\n",
    "        root_node = analyzer.root\n",
    "\n",
    "        json_output = json.dumps(node_to_dict(root_node), indent=2)\n",
    "\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json_file.write(json_output)\n",
    "\n",
    "        print(f\"Analyzed and saved JSON for: {file_path}\")\n",
    "        return analyzer.root\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing file {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def node_to_dict(node: Node) -> dict:\n",
    "    result = {\n",
    "        \"type\": node.type,\n",
    "        \"content\": node.content,\n",
    "        \"children\": [node_to_dict(child) for child in node.children],\n",
    "        \"line_number\": node.line_number,\n",
    "        \"end_line_number\": node.end_line_number,\n",
    "        \"indent_level\": node.indent_level\n",
    "    }\n",
    "    if node.function:\n",
    "        result[\"function\"] = node.function\n",
    "    if node.alias:\n",
    "        result[\"alias\"] = node.alias.dict()\n",
    "    if node.docstring:\n",
    "        result[\"docstring\"] = node.docstring\n",
    "    if node.return_type:\n",
    "        result[\"return_type\"] = node.return_type\n",
    "    return result\n",
    "\n",
    "def map_execution(file_path: str, save_folder: str):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    global_function_defs = {}\n",
    "    analyze_python_file(file_path, save_folder, global_function_defs)\n",
    "\n",
    "    print(f\"Execution map complete. Results saved to {save_folder}\")\n",
    "\n",
    "file_path = \"C:/Users/justl/Documents/VideoDiarization/main_v3.py\"\n",
    "save_folder = \"analysis_output\"\n",
    "map_execution(file_path, save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alias(BaseModel):\n",
    "    actual_name: str\n",
    "    alias_name: str\n",
    "    local_file: bool\n",
    "\n",
    "class Node(BaseModel):\n",
    "    type: str\n",
    "    content: str\n",
    "    children: List['Node'] = []\n",
    "    function: Optional[str] = None\n",
    "    alias: Optional[Alias] = None\n",
    "    line_number: Optional[int] = None\n",
    "    end_line_number: Optional[int] = None\n",
    "    docstring: Optional[str] = None\n",
    "    return_type: Optional[str] = None\n",
    "    indent_level: int = 0\n",
    "    def_location: Optional[str] = None\n",
    "\n",
    "class PyFileAnalyzer(ast.NodeVisitor):\n",
    "    def __init__(self, source_code, file_path, save_folder, global_function_defs):\n",
    "        self.root = Node(type=\"module\", content=\"\", children=[])\n",
    "        self.current_node = self.root\n",
    "\n",
    "        self.save_folder = save_folder\n",
    "        self.file_path = file_path\n",
    "        self.folder_path = os.path.dirname(file_path)\n",
    "\n",
    "        self.source_code = source_code.splitlines()\n",
    "\n",
    "        self.alias_dict = {}\n",
    "        # self.variable_types = {}\n",
    "        self.analyzed_files = set()\n",
    "        self.indent_level = 0\n",
    "        \n",
    "        self.file_analyzers = {}\n",
    "        # self.function_defs = {}\n",
    "        # self.current_function_stack = []\n",
    "        # self.global_function_defs = global_function_defs\n",
    "\n",
    "    def get_node_content(self, node):\n",
    "        start_line = node.lineno - 1\n",
    "        end_line = node.end_lineno\n",
    "        content = '\\n'.join(self.source_code[start_line:end_line]).strip()\n",
    "        return content\n",
    "\n",
    "    def visit_Import(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        for alias in node.names:\n",
    "            tmp_local_file_path = alias.name.replace('.', os.path.sep) + \".py\"\n",
    "            tmp_abs_file_path = os.path.join(self.folder_path, tmp_local_file_path)\n",
    "\n",
    "            local_file = os.path.exists(tmp_abs_file_path)\n",
    "\n",
    "            if local_file and tmp_abs_file_path not in self.analyzed_files:\n",
    "                self.analyzed_files.add(tmp_abs_file_path)\n",
    "                root = analyze_python_file(tmp_abs_file_path, self.save_folder)\n",
    "                self.file_analyzers[tmp_abs_file_path] = root\n",
    "\n",
    "            new_alias = Alias(actual_name=alias.name, alias_name=alias.asname or alias.name, local_file=local_file)\n",
    "            self.alias_dict[alias.asname or alias.name] = new_alias\n",
    "\n",
    "            import_node = Node(\n",
    "                type=\"import\",\n",
    "                content=content,\n",
    "                line_number=node.lineno,\n",
    "                end_line_number=node.end_lineno,\n",
    "                alias=new_alias,\n",
    "                indent_level=self.indent_level\n",
    "            )\n",
    "            self.current_node.children.append(import_node)\n",
    "\n",
    "    def visit_ImportFrom(self, node):\n",
    "        content = self.get_node_content(node)\n",
    "        module = node.module or \"\"\n",
    "        \n",
    "        tmp_local_file_path = module.replace('.', os.path.sep) + \".py\"\n",
    "        tmp_abs_file_path = os.path.join(self.folder_path, tmp_local_file_path)\n",
    "\n",
    "        local_file = os.path.exists(tmp_abs_file_path)\n",
    "\n",
    "        if local_file and tmp_abs_file_path not in self.analyzed_files:\n",
    "            self.analyzed_files.add(tmp_abs_file_path)\n",
    "            root = analyze_python_file(tmp_abs_file_path, self.save_folder)\n",
    "            self.file_analyzers[tmp_abs_file_path] = root\n",
    "\n",
    "\n",
    "        if len(node.names) == 1 and node.names[0].name == '*':\n",
    "            self.handle_star_import(module, tmp_abs_file_path if local_file else None)\n",
    "        else:\n",
    "            for alias in node.names:\n",
    "                new_alias = Alias(\n",
    "                    actual_name=f\"{module}.{alias.name}\", \n",
    "                    alias_name=alias.asname or alias.name, \n",
    "                    local_file=local_file\n",
    "                )\n",
    "                self.alias_dict[alias.asname or alias.name] = new_alias\n",
    "\n",
    "                import_node = Node(\n",
    "                    type=\"import\",\n",
    "                    content=content,\n",
    "                    line_number=node.lineno,\n",
    "                    end_line_number=node.end_lineno,\n",
    "                    alias=new_alias,\n",
    "                    indent_level=self.indent_level\n",
    "                )\n",
    "                self.current_node.children.append(import_node)\n",
    "\n",
    "    def handle_star_import(self, module_name, module_path):\n",
    "        if module_path:\n",
    "            with open(module_path, 'r') as file:\n",
    "                module_ast = ast.parse(file.read())\n",
    "            names = self.get_module_names(module_ast)\n",
    "        else:\n",
    "            try:\n",
    "                module = importlib.import_module(module_name)\n",
    "                names = dir(module)\n",
    "            except ImportError:\n",
    "                print(f\"Warning: Unable to import module {module_name}\")\n",
    "                return\n",
    "\n",
    "        for name in names:\n",
    "            if not name.startswith('_'):\n",
    "                new_alias = Alias(\n",
    "                    actual_name=f\"{module_name}.{name}\",\n",
    "                    alias_name=name,\n",
    "                    local_file=bool(module_path)\n",
    "                )\n",
    "                self.alias_dict[name] = new_alias\n",
    "\n",
    "    def get_module_names(self, module_ast):\n",
    "        names = []\n",
    "        for node in module_ast.body:\n",
    "            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n",
    "                names.append(node.name)\n",
    "        return names\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
